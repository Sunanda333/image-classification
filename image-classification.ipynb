{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHaHv9dP_mFW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "xMSLshJO_pGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(dataset):\n",
        "    dataset = dataset.reshape(dataset.shape[0], 28, 28, 1)\n",
        "    dataset = dataset.astype(\"float32\") / 255\n",
        "    return dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfcyQjAE_rKV",
        "outputId": "1e01451e-7941-480b-e970-ac77e6c554b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "clean_images = np.concatenate((train_images,test_images), axis=0)\n",
        "clean_images = preprocess(clean_images)\n",
        "\n",
        "clean_labels = np.concatenate((train_labels,test_labels), axis=0)"
      ],
      "metadata": {
        "id": "qKriawKP_vKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "clean_dataset = list(zip(clean_images, clean_labels))\n",
        "random.shuffle(clean_dataset)"
      ],
      "metadata": {
        "id": "m9BAUkmz_xbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=5, strides=2, padding='same', activation=\"relu\")(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=5, strides=2, padding='same', activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=128, kernel_size=4, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "jBNoospr_-Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"/content/training_with_clean_data.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\",\n",
        "        mode='min'),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        verbose=0,\n",
        "        mode='min'\n",
        "    )\n",
        "]\n",
        "\n",
        "model.fit(clean_images, clean_labels, epochs=50, batch_size=64, validation_split=0.2, callbacks = callbacks)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y68uZYeAIdZ",
        "outputId": "5d5de8eb-764c-4883-bf79-6aa8d3a2475a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "875/875 [==============================] - 17s 18ms/step - loss: 0.2066 - accuracy: 0.9356 - val_loss: 0.0467 - val_accuracy: 0.9864\n",
            "Epoch 2/50\n",
            "875/875 [==============================] - 15s 17ms/step - loss: 0.0689 - accuracy: 0.9780 - val_loss: 0.0394 - val_accuracy: 0.9879\n",
            "Epoch 3/50\n",
            "875/875 [==============================] - 15s 17ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.0297 - val_accuracy: 0.9908\n",
            "Epoch 4/50\n",
            "875/875 [==============================] - 15s 17ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.0329 - val_accuracy: 0.9904\n",
            "Epoch 5/50\n",
            "875/875 [==============================] - 14s 16ms/step - loss: 0.0381 - accuracy: 0.9879 - val_loss: 0.0394 - val_accuracy: 0.9889\n",
            "Epoch 6/50\n",
            "875/875 [==============================] - 15s 17ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.0281 - val_accuracy: 0.9911\n",
            "Epoch 7/50\n",
            "875/875 [==============================] - 14s 16ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0271 - val_accuracy: 0.9919\n",
            "Epoch 8/50\n",
            "875/875 [==============================] - 14s 16ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0284 - val_accuracy: 0.9924\n",
            "Epoch 9/50\n",
            "875/875 [==============================] - 15s 17ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0227 - val_accuracy: 0.9942\n",
            "Epoch 10/50\n",
            "875/875 [==============================] - 14s 16ms/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 0.0267 - val_accuracy: 0.9921\n",
            "Epoch 11/50\n",
            "875/875 [==============================] - 14s 17ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0241 - val_accuracy: 0.9922\n",
            "Epoch 12/50\n",
            "875/875 [==============================] - 14s 16ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
            "Epoch 13/50\n",
            "875/875 [==============================] - 15s 17ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0269 - val_accuracy: 0.9926\n",
            "Epoch 14/50\n",
            "875/875 [==============================] - 14s 16ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0243 - val_accuracy: 0.9933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4e8bf82a90>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "# data_dir = os.path.join(gdrive_dir, 'My Drive')\n",
        "# filename1 = '636_project1_train_images'\n",
        "# filename2 = '636_project1_train_labels'\n",
        "noisy_images = pickle.load(open(os.path.join(\"/content/636_project1_train_images\"),'rb'))\n",
        "noisy_labels = pickle.load(open(os.path.join(\"/content/636_project1_train_labels\"),'rb'))"
      ],
      "metadata": {
        "id": "xIkO0nwrALrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_images = noisy_images.numpy()\n",
        "noisy_labels = noisy_labels.numpy()\n",
        "noisy_images = preprocess(noisy_images)"
      ],
      "metadata": {
        "id": "Jgk5EbzWAOdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_dataset = list(zip(noisy_images, noisy_labels))\n",
        "random.shuffle(noisy_dataset)"
      ],
      "metadata": {
        "id": "Mvh8ZvAVARMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_train_images = noisy_images[:50000]\n",
        "noisy_test_images = noisy_images[50000:]\n",
        "noisy_train_labels = noisy_labels[:50000]\n",
        "noisy_test_labels = noisy_labels[50000:]"
      ],
      "metadata": {
        "id": "4LTtPQcwAUDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuMan2RxL9XL",
        "outputId": "00d04a85-d3bf-4f6d-c4e2-2dc40f3553f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"/content/training_with_noisy_data.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\",\n",
        "        mode='min'),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        verbose=0,\n",
        "        mode='min'\n",
        "    )\n",
        "]\n",
        "model.fit(noisy_train_images, noisy_train_labels, epochs=50, batch_size=64, callbacks= callbacks, validation_split= 0.2)\n"
      ],
      "metadata": {
        "id": "1yfHOdg3AdJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b643058-2a18-40e5-e3de-e1a632c19d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 2.2190 - accuracy: 0.2758 - val_loss: 1.8937 - val_accuracy: 0.3325\n",
            "Epoch 2/50\n",
            "625/625 [==============================] - 11s 18ms/step - loss: 1.9184 - accuracy: 0.3253 - val_loss: 1.8767 - val_accuracy: 0.3406\n",
            "Epoch 3/50\n",
            "625/625 [==============================] - 11s 18ms/step - loss: 1.8615 - accuracy: 0.3480 - val_loss: 1.7912 - val_accuracy: 0.3727\n",
            "Epoch 4/50\n",
            "625/625 [==============================] - 11s 18ms/step - loss: 1.7477 - accuracy: 0.3907 - val_loss: 1.6336 - val_accuracy: 0.4324\n",
            "Epoch 5/50\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 1.5799 - accuracy: 0.4504 - val_loss: 1.3626 - val_accuracy: 0.5279\n",
            "Epoch 6/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.4888 - accuracy: 0.4856 - val_loss: 1.3085 - val_accuracy: 0.5530\n",
            "Epoch 7/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.4393 - accuracy: 0.5035 - val_loss: 1.3177 - val_accuracy: 0.5503\n",
            "Epoch 8/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.3898 - accuracy: 0.5200 - val_loss: 1.2272 - val_accuracy: 0.5812\n",
            "Epoch 9/50\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 1.3707 - accuracy: 0.5269 - val_loss: 1.2160 - val_accuracy: 0.5843\n",
            "Epoch 10/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.3489 - accuracy: 0.5339 - val_loss: 1.2136 - val_accuracy: 0.5822\n",
            "Epoch 11/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.3269 - accuracy: 0.5418 - val_loss: 1.2047 - val_accuracy: 0.5849\n",
            "Epoch 12/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.3073 - accuracy: 0.5503 - val_loss: 1.2020 - val_accuracy: 0.5871\n",
            "Epoch 13/50\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 1.2959 - accuracy: 0.5549 - val_loss: 1.1759 - val_accuracy: 0.5939\n",
            "Epoch 14/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.2701 - accuracy: 0.5617 - val_loss: 1.1900 - val_accuracy: 0.5856\n",
            "Epoch 15/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.2598 - accuracy: 0.5645 - val_loss: 1.1960 - val_accuracy: 0.5824\n",
            "Epoch 16/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.2417 - accuracy: 0.5740 - val_loss: 1.1698 - val_accuracy: 0.5950\n",
            "Epoch 17/50\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 1.2356 - accuracy: 0.5730 - val_loss: 1.1634 - val_accuracy: 0.5984\n",
            "Epoch 18/50\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 1.2130 - accuracy: 0.5796 - val_loss: 1.2002 - val_accuracy: 0.5798\n",
            "Epoch 19/50\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 1.1984 - accuracy: 0.5853 - val_loss: 1.1974 - val_accuracy: 0.5835\n",
            "Epoch 20/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.1875 - accuracy: 0.5888 - val_loss: 1.2425 - val_accuracy: 0.5674\n",
            "Epoch 21/50\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 1.1743 - accuracy: 0.5955 - val_loss: 1.2021 - val_accuracy: 0.5863\n",
            "Epoch 22/50\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 1.1614 - accuracy: 0.5995 - val_loss: 1.2054 - val_accuracy: 0.5811\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d95095dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(noisy_test_images, noisy_test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "hR8df7PKAf9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e0cae6-b908-466a-e024-35a27192f2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1957 - accuracy: 0.5891\n",
            "Test accuracy: 0.589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to run the Model:\n",
        "\n",
        "\n",
        "*   Run the method preprocessing on the input images\n",
        "*   Run model.evaluate on the given model"
      ],
      "metadata": {
        "id": "7quqo1KWRyZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing the test image dataset\n",
        "test_x = preprocess(test_x)"
      ],
      "metadata": {
        "id": "Ksrh9XWSRzbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running model.evaluate with model\n",
        "from tensorflow import keras\n",
        "# Give the path of the saved model after upload\n",
        "model = keras.models.load_model('model_path_goes_here')\n",
        "\n",
        "model.evaluate(test_x, test_y)"
      ],
      "metadata": {
        "id": "A4ilKjaMR7tj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}